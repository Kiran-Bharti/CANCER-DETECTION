{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import numpy as np \n",
    "\n",
    "SAMPLE_COUNT=85000\n",
    "TRAINING_RATIO=0.9\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 18\n",
    "MODEL_PLOT_FILE = \"model_plot.png\"\n",
    "EPOCHS = 10\n",
    "VERBOSITY = 1\n",
    "MODEL_FILE = \"model.h5\"\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "TRAINING_PLOT_FILE = \"training.png\"\n",
    "VALIDATION_PLOT_FILE = \"validation.png\"\n",
    "ROC_PLOT_FILE = \"roc.png\"\n",
    "TESTING_BATCH_SIZE = 5000\n",
    "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\"\n",
    "\n",
    "def datasetup(SAMPLE_COUNT, TRAINING_RATIO):    \n",
    "    training_dir = 'static\\\\train\\\\'\n",
    "    data_frame = pd.DataFrame({'path': glob(os.path.join(training_dir,'*.tif'))})\n",
    "    data_frame['id'] = data_frame.path.map(lambda x: x.split('\\\\')[2].split('.')[0]) \n",
    "    labels = pd.read_csv('traindata\\\\train_labels.csv')\n",
    "    data_frame = data_frame.merge(labels, on = 'id')\n",
    "    negatives = data_frame[data_frame.label == 0].sample(SAMPLE_COUNT)\n",
    "    positives = data_frame[data_frame.label == 1].sample(SAMPLE_COUNT)\n",
    "    data_frame = pd.concat([negatives, positives]).reset_index()\n",
    "    data_frame = data_frame[['path', 'id', 'label']]\n",
    "    data_frame['image'] = data_frame['path'].map(imread)\n",
    "    #small_data_frame=data_frame[0:10]\n",
    "    #small_frame=data_frame[85000:85010]\n",
    "    #smalldata_frame=pd.concat([small_data_frame, small_frame]).reset_index()\n",
    "    #smalldata_frame = smalldata_frame[['path', 'id', 'label']]\n",
    "    #smalldata_frame['image'] = smalldata_frame['path'].map(imread)\n",
    "    training_path = '../training'\n",
    "    validation_path = '../validation'\n",
    "    for folder in [training_path, validation_path]:\n",
    "        for subfolder in ['0', '1']:\n",
    "            path = os.path.join(folder, subfolder)\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "    training, validation = train_test_split(data_frame, train_size=TRAINING_RATIO, stratify=data_frame['label'])\n",
    "    data_frame.set_index('id', inplace=True)\n",
    "    for images_and_path in [(training, training_path), (validation, validation_path)]:\n",
    "        images = images_and_path[0]\n",
    "        path = images_and_path[1]\n",
    "        for image in images['id'].values:\n",
    "            file_name = image + '.tif'\n",
    "            label = str(data_frame.loc[image,'label'])\n",
    "            destination = os.path.join(path, label, file_name)\n",
    "            if not os.path.exists(destination):\n",
    "                source = os.path.join('static/train', file_name)\n",
    "                shutil.copyfile(source, destination)\n",
    "\n",
    "    return (training_path, validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "training_path, validation_path=datasetup(SAMPLE_COUNT, TRAINING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            rotation_range=180,\n",
    "                                            zoom_range=0.4, \n",
    "                                            width_shift_range=0.3,\n",
    "                                            height_shift_range=0.3,\n",
    "                                            shear_range=0.3,\n",
    "                                            channel_shift_range=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(IMAGE_SIZE, BATCH_SIZE, training_data_generator,training_path, validation_path):\n",
    "    training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                    batch_size=BATCH_SIZE,\n",
    "                                                                    class_mode='binary')\n",
    "    validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                                target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                                batch_size=BATCH_SIZE,\n",
    "                                                                                class_mode='binary')\n",
    "    testing_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                            target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                            batch_size=BATCH_SIZE,\n",
    "                                                                            class_mode='binary',\n",
    "                                                                            shuffle=False)\n",
    "    return (training_generator, validation_generator, testing_generator)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 219745 images belonging to 2 classes.\n",
      "Found 94055 images belonging to 2 classes.\n",
      "Found 94055 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_generator, validation_generator, testing_generator=generation(IMAGE_SIZE, BATCH_SIZE, training_data_generator,training_path, validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancermodel(IMAGE_SIZE, MODEL_PLOT_FILE):     \n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    inputs = Input(input_shape)\n",
    "    xception = Xception(include_top=False, input_shape=input_shape)(inputs)\n",
    "    nas_net = NASNetMobile(include_top=False, input_shape=input_shape)(inputs)\n",
    "    outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), GlobalAveragePooling2D()(nas_net)])\n",
    "    outputs = Dropout(0.5)(outputs)\n",
    "    outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    #plot_model(model,\n",
    "    #        to_file=MODEL_PLOT_FILE,\n",
    "    #        show_shapes=True,\n",
    "    #        show_layer_names=True)     \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 7, 7, 2048)   20861480    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 7, 7, 1056)   4269716     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3104)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3104)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            3105        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,134,301\n",
      "Trainable params: 25,043,035\n",
      "Non-trainable params: 91,266\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=cancermodel(IMAGE_SIZE, MODEL_PLOT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(EPOCHS, VERBOSITY, MODEL_FILE, TRAINING_LOGS_FILE, training_generator, validation_generator, model):       \n",
    "    history = model.fit_generator(training_generator,\n",
    "                                steps_per_epoch=len(training_generator), \n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=len(validation_generator),\n",
    "                                epochs=EPOCHS,\n",
    "                                verbose=VERBOSITY,\n",
    "                                callbacks=[PlotLossesKeras(),\n",
    "                                            ModelCheckpoint(MODEL_FILE,\n",
    "                                                            monitor='val_acc',\n",
    "                                                            verbose=VERBOSITY,\n",
    "                                                            save_best_only=True,\n",
    "                                                            mode='max'),\n",
    "                                            CSVLogger(TRAINING_LOGS_FILE,\n",
    "                                                    append=False,\n",
    "                                                    separator=';')])\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  27/6868 [..............................] - ETA: 1045:44:46 - loss: 0.6088 - acc: 0.6562"
     ]
    }
   ],
   "source": [
    "history=training(EPOCHS, VERBOSITY, MODEL_FILE, TRAINING_LOGS_FILE, training_generator, validation_generator, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
